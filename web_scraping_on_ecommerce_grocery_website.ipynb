{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping with BeautifulSoup and Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "\n",
    "#### python 3.6\n",
    "#### chromedriver <-- a Chrome browser engine to initialize Chrome for automated running of Selenium-related script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prerequisites\n",
    "\n",
    "import requests  #for handling HTTP requests\n",
    "from bs4 import BeautifulSoup  #for parsing HTML\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define website url which I am going to scrape\n",
    "url = \"https://www.ztore.com/en/category/all/jetso-zone/full-case-offer\"\n",
    "base_url = \"https://www.ztore.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chrome session\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "driver.implicitly_wait(30) #tell WebDriver to elapse 30 seconds when trying to find any element (or elements) not immediately available\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After opening the url above, Selenium browser automator will search and click \"viewAllButton\" button\n",
    "#to display more products. If no such button element, then ignore this exceptional case\n",
    "try:\n",
    "    python_button = driver.find_element_by_class_name('viewAllButton')\n",
    "    python_button.click()#clicklink\n",
    "except NoSuchElementException:\n",
    "    print (\"Note that there's no 'viewAllButton' in this page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to build and maintain an efficient automated web scraper, firstly we need to understand the structure of the website, e.g. html source code, XPath, etc.\n",
    "#### (p.s. click F12 to inspect the element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's no more products at the bottom of this page.\n"
     ]
    }
   ],
   "source": [
    "#Keep scrolling down page until display all products (URLs)\n",
    "\n",
    "x = 48   #in ztore category page, the number of product display on screen before 'viewAllButton' is up to 48\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        xpath = \"//body/div[1]/div/div/div[3]/div[3]/div/div/div[\"\n",
    "        #xpath of the last product shown in the display page\n",
    "        #in case of error, try to replace with this xpath => \"//body/div[1]/div/div/div[3]/div[2]/div/div/div[\"\n",
    "        xpath += str(x)\n",
    "        xpath += \"]\"\n",
    "        element = driver.find_element_by_xpath(xpath)\n",
    "        ActionChains(driver).move_to_element(element).perform()\n",
    "        driver.execute_script(\"window.scrollBy(0, -150);\")\n",
    "        time.sleep(2)\n",
    "        x+=10\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        print (\"There's no more products at the bottom of this page.\")\n",
    "        break\n",
    "\n",
    "time.sleep(5)  #set browser to wait 5 seconds before executing next request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We finally fetched 470 products URLs.\n"
     ]
    }
   ],
   "source": [
    "#Gather all the category products URLs on the web page at once\n",
    "food_containers = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "products_urls = [base_url + link.a.get('href') for link in food_containers.findAll(\"div\", class_ = \"jsx-1585925611 ProductItem\")]\n",
    "\n",
    "print(\"We finally fetched \" + str(len(products_urls)) + \" products URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ztore.com/en/product/water-dispenser-with-distilled-water-6000220-c1174',\n",
       " 'https://www.ztore.com/en/product/water-dispenser-with-distilled-water-white-6000230-c1174',\n",
       " 'https://www.ztore.com/en/product/instant-noodle-sesame-oil-8000117-c1174',\n",
       " 'https://www.ztore.com/en/product/oolong-tea-8000143-c1174',\n",
       " 'https://www.ztore.com/en/product/rtd-coffee-with-milk-sugar-8000146-c1174']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a look into the first 5 scraped product urls:\n",
    "products_urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We would like to retrieve product details from each product page url, including:\n",
    "#### - Brand name\n",
    "#### - Main Category\n",
    "#### - Sub-category\n",
    "#### - Product Name\n",
    "#### - Country of origin\n",
    "#### - Number of reviews\n",
    "#### - Rating score (0 - 5)\n",
    "#### - Price  <- original price/ promotional price (if any)\n",
    "#### - Main image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define field of product details\n",
    "brand = []\n",
    "main_cat = []  #main category\n",
    "sub_cat = []   #sub category\n",
    "product_name = []\n",
    "country_of_origin = []\n",
    "rating = []    #rating score (0-5)\n",
    "rating_count = []   #number of reviews\n",
    "price = []  \n",
    "img_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to request and parse a HTML web page\n",
    "def getAndParseURL(url):\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    return(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping is completed.\n",
      "Wall time: 2h 54min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Scrape data from every product URL:\n",
    "#Set browser to wait 3 seconds each time before sending new request to avoid overloading of website\n",
    "\n",
    "for url in products_urls:\n",
    "    soup = getAndParseURL(url)\n",
    "    \n",
    "    #brand\n",
    "    for link in soup.find(\"div\", class_ = \"jsx-923637705 brand\"):\n",
    "        brand.append(link.string)\n",
    "        time.sleep(3)\n",
    "    \n",
    "    #main category\n",
    "    main_cat.append(soup.findAll(type = 'text')[1]['value'])\n",
    "    \n",
    "    #sub-category\n",
    "    sub_cat.append(soup.findAll(type = 'text')[2]['value'])\n",
    "    \n",
    "    #product name\n",
    "    product_name.append(soup.find(\"div\", class_ = \"jsx-923637705 name\").text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #country of origin\n",
    "    country_of_origin.append(soup.find(\"div\", class_ = \"jsx-923637705 info-row-country\").text)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #rating\n",
    "    rating.append(soup.find(\"span\", {\"class\": \"jsx-923637705 rating\"}).text.strip())\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #rating_count (number of reviews)\n",
    "    rating_count.append(soup.find(\"span\", {\"class\": \"jsx-923637705 rating-count\"}).text[1:-9])\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #price (original/promotion price w/o '$' sign)\n",
    "    #get promotional price if any, otherwise get original price\n",
    "    try:\n",
    "        price.append(soup.find(\"span\", {\"class\": \"jsx-923637705 promotion\"}).text[1:])\n",
    "        time.sleep(3)\n",
    "    except AttributeError:\n",
    "        price.append(soup.find(\"div\", {\"class\": \"jsx-923637705 price\"}).text[1:])\n",
    "        time.sleep(3)\n",
    "    \n",
    "    #main image url\n",
    "    for link in soup.find(\"div\", class_ = \"jsx-462475733 product-image-wrapper\"):\n",
    "        img_url.append(link.find('img')['src'])\n",
    "        time.sleep(3)\n",
    "\n",
    "print (\"Scraping is completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the browser session\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 12 image urls.\n"
     ]
    }
   ],
   "source": [
    "#Remove redundant image urls (ending with '.svg') before loading data to dataframe\n",
    "svg_count = 0\n",
    "\n",
    "for link in img_url:\n",
    "    if link.endswith(\".svg\"):\n",
    "        img_url.remove(link)\n",
    "        svg_count+=1\n",
    "        \n",
    "print(\"Removed \" + str(svg_count) + \" image urls.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe with scraped data\n",
    "scraped_data = pd.DataFrame({'brand': brand,\n",
    "                             'main_category': main_cat,\n",
    "                             'sub_category': sub_cat,                          \n",
    "                             'product_name': product_name,\n",
    "                             'country_of_origin': country_of_origin,\n",
    "                             \"rating\": rating,\n",
    "                             \"number_of_reviews\": rating_count,\n",
    "                             \"price\": price,\n",
    "                             \"img_url\": img_url\n",
    "                             }, columns=['brand', 'main_category','sub_category', 'product_name',\n",
    "                                         'country_of_origin', 'rating', 'number_of_reviews', \n",
    "                                         'price', 'img_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if any missing values inside each dataframe column\n",
    "#scraped_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic data wrangling\n",
    "scraped_data['rating'] = scraped_data['rating'].replace(\"\", 0)   #replace null rating score with 0\n",
    "scraped_data['product_name'] = scraped_data['product_name'].replace(\"xa0\", \"\")   #for cleaning messy product name\n",
    "scraped_data.drop_duplicates(keep='first', inplace=True)   #remove duplicated row record(s) if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>country_of_origin</th>\n",
       "      <th>rating</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>price</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WATSONS</td>\n",
       "      <td>Water</td>\n",
       "      <td>Distilled Water</td>\n",
       "      <td>WATER DISPENSER WITH DISTILLED WATER (BLACK) SET</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>4.5</td>\n",
       "      <td>51</td>\n",
       "      <td>488.00</td>\n",
       "      <td>https://cdn.ztore.com/images/ztore/production/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WATSONS</td>\n",
       "      <td>Water</td>\n",
       "      <td>Distilled Water</td>\n",
       "      <td>WATER DISPENSER WITH DISTILLED WATER (WHITE) SET</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>4.3</td>\n",
       "      <td>33</td>\n",
       "      <td>488.00</td>\n",
       "      <td>https://cdn.ztore.com/images/ztore/production/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE-MA-E</td>\n",
       "      <td>Noodle &amp; Pasta</td>\n",
       "      <td>Instant Noodle-Japanese</td>\n",
       "      <td>INSTANT NOODLE-SESAME OIL 100GX30</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>4.8</td>\n",
       "      <td>120</td>\n",
       "      <td>92.90</td>\n",
       "      <td>https://cdn.ztore.com/images/ztore/production/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROBIFF</td>\n",
       "      <td>RTD -Tea &amp; Lemon Tea</td>\n",
       "      <td>PET-Green Tea, Red Tea and Fruit Tea</td>\n",
       "      <td>OOLONG TEA 500MLX24</td>\n",
       "      <td>China</td>\n",
       "      <td>4.8</td>\n",
       "      <td>994</td>\n",
       "      <td>145.00</td>\n",
       "      <td>https://cdn.ztore.com/images/ztore/production/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NESCAFE</td>\n",
       "      <td>RTD-Coffee &amp; Milk Tea</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>RTD COFFEE WITH MILK &amp; SUGAR-CASE 250MLX24</td>\n",
       "      <td>China</td>\n",
       "      <td>4.8</td>\n",
       "      <td>862</td>\n",
       "      <td>128.00</td>\n",
       "      <td>https://cdn.ztore.com/images/ztore/production/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     brand          main_category                          sub_category  \\\n",
       "0  WATSONS                  Water                       Distilled Water   \n",
       "1  WATSONS                  Water                       Distilled Water   \n",
       "2  DE-MA-E         Noodle & Pasta               Instant Noodle-Japanese   \n",
       "3   ROBIFF   RTD -Tea & Lemon Tea  PET-Green Tea, Red Tea and Fruit Tea   \n",
       "4  NESCAFE  RTD-Coffee & Milk Tea                                Coffee   \n",
       "\n",
       "                                       product_name country_of_origin rating  \\\n",
       "0  WATER DISPENSER WITH DISTILLED WATER (BLACK) SET          Multiple    4.5   \n",
       "1  WATER DISPENSER WITH DISTILLED WATER (WHITE) SET          Multiple    4.3   \n",
       "2                 INSTANT NOODLE-SESAME OIL 100GX30         Hong Kong    4.8   \n",
       "3                               OOLONG TEA 500MLX24             China    4.8   \n",
       "4        RTD COFFEE WITH MILK & SUGAR-CASE 250MLX24             China    4.8   \n",
       "\n",
       "  number_of_reviews   price                                            img_url  \n",
       "0                51  488.00  https://cdn.ztore.com/images/ztore/production/...  \n",
       "1                33  488.00  https://cdn.ztore.com/images/ztore/production/...  \n",
       "2               120   92.90  https://cdn.ztore.com/images/ztore/production/...  \n",
       "3               994  145.00  https://cdn.ztore.com/images/ztore/production/...  \n",
       "4               862  128.00  https://cdn.ztore.com/images/ztore/production/...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check dataframe structure\n",
    "scraped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "img_url              0\n",
       "price                0\n",
       "number_of_reviews    0\n",
       "rating               0\n",
       "country_of_origin    0\n",
       "product_name         0\n",
       "sub_category         0\n",
       "main_category        0\n",
       "brand                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if still any missing values inside each dataframe column\n",
    "scraped_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv\n",
    "scraped_data.to_csv('scraped_ztore_product_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally scraped 464 products.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#wrap up scraping result\n",
    "print(\"Totally scraped \" + str(len(scraped_data.index)) + \" products.\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "Web scraping can be seen as a data collection exercise. In the above example, I have retrieved a total of 464 full case products information from specific product page in Ztore. During the process, our crawler should always be 'polite' to the website by adhering to robots.txt protocol.\n",
    "\n",
    "For me, one of the most awkward parts was to identify the website scrolling behavior. In Ztore case, it is necessary for crawler to scroll page infinitely in order to fetch all product urls. Therefore, I have made some tricky steps to simulate human-like actions in the Selenium browser session so that the next page element could be called continously.\n",
    "\n",
    "After data collection and prelim data cleaning (a.k.a. data preprocessing), we can move to Exploratory Data Analysis (EDA) to uncover characteristic of our data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
